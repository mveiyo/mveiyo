{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNUVM5NY11eOaZ2o4XGEuxc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mveiyo/mveiyo/blob/main/Document_Binarization_Collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J179N790QLJW",
        "outputId": "96e3abed-33f8-42a0-98af-c50e9ef8b539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Document_Binarization_Collection'...\n",
            "remote: Enumerating objects: 805, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 805 (delta 14), reused 35 (delta 14), pack-reused 770\u001b[K\n",
            "Receiving objects: 100% (805/805), 434.26 MiB | 38.16 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n",
            "Updating files: 100% (726/726), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/RichSu95/Document_Binarization_Collection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Train\n",
        "import os\n",
        "from time import time\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "from data import ImageFolder\n",
        "from framework import MyFrame\n",
        "from loss import dice_bce_loss\n",
        "\n",
        "# from networks.unet import UNet\n",
        "# from networks.dunet import DUNet\n",
        "from networks.dplinknet import LinkNet34, DLinkNet34, DPLinkNet34\n",
        "\n",
        "SHAPE = (256, 256)\n",
        "DATA_NAME = \"DIBCO\"  # BickleyDiary, DIBCO, PLM\n",
        "DEEP_NETWORK_NAME = \"DPLinkNet34\"\n",
        "print(\"Now training dataset: {}, using network model: {}\".format(DATA_NAME, DEEP_NETWORK_NAME))\n",
        "\n",
        "train_root = \"Document_Binarization_Collection/DP-LinkNet/data/train/\"\n",
        "imagelist = list(filter(lambda x: x.find(\"img\") != -1, os.listdir(train_root)))\n",
        "trainlist = list(map(lambda x: x[:-8], imagelist))\n",
        "log_name = DATA_NAME.lower() + \"_\" + DEEP_NETWORK_NAME.lower()\n",
        "\n",
        "BATCHSIZE_PER_CARD = 32\n",
        "\n",
        "if DEEP_NETWORK_NAME == \"DPLinkNet34\":\n",
        "    solver = MyFrame(DPLinkNet34, dice_bce_loss, 2e-4)\n",
        "elif DEEP_NETWORK_NAME == \"DLinkNet34\":\n",
        "    solver = MyFrame(DLinkNet34, dice_bce_loss, 2e-4)\n",
        "elif DEEP_NETWORK_NAME == \"LinkNet34\":\n",
        "    solver = MyFrame(LinkNet34, dice_bce_loss, 2e-4)\n",
        "else:\n",
        "    print(\"Deep network not found, please have a check!\")\n",
        "    exit(0)\n",
        "\n",
        "batchsize = torch.cuda.device_count() * BATCHSIZE_PER_CARD\n",
        "\n",
        "dataset = ImageFolder(trainlist, train_root)\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batchsize,\n",
        "    shuffle=True,\n",
        "    num_workers=4)\n",
        "\n",
        "mylog = open(\"Document_Binarization_Collection/DP-LinkNet/logs\" + log_name + \".log\", \"w\")\n",
        "no_optim = 0\n",
        "total_epoch = 500\n",
        "train_epoch_best_loss = 100.\n",
        "\n",
        "tic = time()\n",
        "for epoch in range(1, total_epoch + 1):\n",
        "    data_loader_iter = iter(data_loader)\n",
        "    train_epoch_loss = 1\n",
        "    '''for img, mask in data_loader_iter:\n",
        "        solver.set_input(img, mask)\n",
        "        train_loss = solver.optimize()\n",
        "        train_epoch_loss += train_loss\n",
        "'''\n",
        "for img, mask in data_loader_iter:\n",
        "    try:\n",
        "        solver.set_input(img, mask)\n",
        "        train_loss = solver.optimize()\n",
        "        train_epoch_loss += train_loss\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "    train_epoch_loss /= len(data_loader_iter)\n",
        "    print(\"********\", file=mylog)\n",
        "    print(\"epoch:\", epoch, \"    time:\", int(time() - tic), file=mylog)\n",
        "    print(\"train_loss:\", train_epoch_loss, file=mylog)\n",
        "    print(\"SHAPE:\", SHAPE, file=mylog)\n",
        "    print(\"********\")\n",
        "    print(\"epoch:\", epoch, \"    time:\", int(time() - tic))\n",
        "    print(\"train_loss:\", train_epoch_loss)\n",
        "    print(\"SHAPE:\", SHAPE)\n",
        "\n",
        "    if train_epoch_loss >= train_epoch_best_loss:\n",
        "        no_optim += 1\n",
        "    else:\n",
        "        no_optim = 0\n",
        "        train_epoch_best_loss = train_epoch_loss\n",
        "        solver.save(\"Document_Binarization_Collection/DP-LinkNet/weights/\" + log_name + \".th\")\n",
        "\n",
        "    if no_optim > 20:\n",
        "        print(\"early stop at %d epoch\" % epoch, file=mylog)\n",
        "        print(\"early stop at %d epoch\" % epoch)\n",
        "        break\n",
        "\n",
        "    if no_optim > 10:\n",
        "        if solver.old_lr < 1e-7:\n",
        "            break\n",
        "        solver.load(\"Document_Binarization_Collection/DP-LinkNet/weights/\" + log_name + \".th\")\n",
        "        solver.update_lr(5.0, factor=True, mylog=mylog)\n",
        "    mylog.flush()\n",
        "\n",
        "print(\"Finish!\", file=mylog)\n",
        "print(\"Finish!\")\n",
        "mylog.close()"
      ],
      "metadata": {
        "id": "GPqnSoMaMyBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare dataset for training\n",
        "\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "\n",
        "from utils import get_patches\n",
        "\n",
        "TILE_SIZE = 256\n",
        "print(\"Image patch size:\", TILE_SIZE, \"x\", TILE_SIZE)\n",
        "\n",
        "data_root_image = \"Document_Binarization_Collection/DP-LinkNet/dataset\"\n",
        "data_root_mask = \"Document_Binarization_Collection/DP-LinkNet/data_GT\"\n",
        "data_save = \"Document_Binarization_Collection/DP-LinkNet/data\"\n",
        "img_list = os.listdir(data_root_image)\n",
        "img_list.sort()\n",
        "\n",
        "data_train_dir = os.path.join(data_save, \"train\")\n",
        "if not os.path.exists(data_train_dir):\n",
        "    os.makedirs(data_train_dir)\n",
        "\n",
        "# img_patches, msk_patches = [], []  # patches for each image or ground truth\n",
        "total_img_patches, total_msk_patches = [], []  # patches for all the images or ground truths\n",
        "\n",
        "for idx in range(len(img_list)):\n",
        "    if os.path.isdir(os.path.join(data_root_image, img_list[idx])):\n",
        "        continue\n",
        "\n",
        "    print(\"Now processing image:\", os.path.join(data_root_image, img_list[idx]))\n",
        "    (fname, fext) = os.path.splitext(img_list[idx])\n",
        "    img = cv2.imread(os.path.join(data_root_image, img_list[idx]))\n",
        "    msk = cv2.imread(os.path.join(data_root_mask, fname + \".png\"))\n",
        "\n",
        "    # extract the patches from the original document images and the corresponding ground truths\n",
        "    img_patch_locations, img_patches = get_patches(img, TILE_SIZE, TILE_SIZE)\n",
        "    msk_patch_locations, msk_patches = get_patches(msk, TILE_SIZE, TILE_SIZE)\n",
        "\n",
        "    print(\"Patches extracted:\", len(img_patches))\n",
        "    for idy in range(len(img_patches)):\n",
        "        total_img_patches.append(img_patches[idy])\n",
        "        total_msk_patches.append(msk_patches[idy])\n",
        "\n",
        "print(\"Total number of train patches:\", len(total_img_patches))\n",
        "for idz in range(len(total_img_patches)):\n",
        "    cv2.imwrite(os.path.join(data_train_dir, str(idz) + \"_img.png\"), total_img_patches[idz])\n",
        "    cv2.imwrite(os.path.join(data_train_dir, str(idz) + \"_mask.png\"), total_msk_patches[idz])\n",
        "\n",
        "print(\"Done\")\n"
      ],
      "metadata": {
        "id": "JAOzjZOwMtPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "# Load and display an image (replace 'your_image.jpg' with the actual image file path)\n",
        "img = cv2.imread('Document_Binarization_Collection/DP-LinkNet/dataset/3.png')\n",
        "\n",
        "if img is not None:\n",
        "    cv2_imshow(img)\n",
        "else:\n",
        "    print(\"Error: Image not loaded successfully.\")"
      ],
      "metadata": {
        "id": "BND22YLfo6eO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98750bf6-360e-43ef-8d48-7a765e2fee2b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Image not loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -r Document_Binarization_Collection/DP-LinkNet/requirements.txt\n",
        "if img is not None:\n",
        "    # Now you can safely access the shape of the image and proceed with processing.\n",
        "    img_shape = img.shape\n",
        "    # Rest of your code for processing the image...\n",
        "else:\n",
        "    # Handle the case where the image wasn't loaded correctly.\n",
        "    print(\"Error: Image not loaded successfully.\")"
      ],
      "metadata": {
        "id": "zbR91sUyRH5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1188592a-d10d-4d0a-fe2f-1856ea300d87"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Image not loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creat folder called dataset,data and data_GT\n",
        "#change path in data_prepare.py\n",
        "#upload ground truth images and original images\n",
        "import os\n",
        "\n",
        "# Define the folder names\n",
        "folders = ['dataset', 'data', 'data_GT', 'train', 'weights', 'test_set']\n",
        "\n",
        "# Specify the path to the root directory in Colab\n",
        "root_dir = 'Document_Binarization_Collection/DP-LinkNet'\n",
        "\n",
        "# Create the folders if they don't exist\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(root_dir, folder)\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "\n",
        "# Check if the folders are created\n",
        "print(\"Folders created:\", folders)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRwE6Km98NqW",
        "outputId": "ad170788-d01f-48f9-844e-37f392033ca8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folders created: ['dataset', 'data', 'data_GT', 'train']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Document_Binarization_Collection/DP-LinkNet/data_prepare.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR56hXCfT48h",
        "outputId": "b5e9d7d4-05ec-4257-85a3-770bc48239ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image patch size: 256 x 256\n",
            "Now processing image: Document_Binarization_Collection/DP-LinkNet/dataset/IMG-20230804-WA0005.png\n",
            "Patches extracted: 48\n",
            "Now processing image: Document_Binarization_Collection/DP-LinkNet/dataset/IMG-20230804-WA0006.png\n",
            "Patches extracted: 48\n",
            "Now processing image: Document_Binarization_Collection/DP-LinkNet/dataset/IMG-20230804-WA0007.png\n",
            "Patches extracted: 48\n",
            "Now processing image: Document_Binarization_Collection/DP-LinkNet/dataset/IMG-20230804-WA0008.png\n",
            "Patches extracted: 48\n",
            "Now processing image: Document_Binarization_Collection/DP-LinkNet/dataset/IMG-20230804-WA0009.png\n",
            "Patches extracted: 48\n",
            "Now processing image: Document_Binarization_Collection/DP-LinkNet/dataset/IMG-20230804-WA0010.png\n",
            "Patches extracted: 48\n",
            "Now processing image: Document_Binarization_Collection/DP-LinkNet/dataset/IMG-20230804-WA0011.png\n",
            "Patches extracted: 48\n",
            "Now processing image: Document_Binarization_Collection/DP-LinkNet/dataset/IMG-20230804-WA0012.png\n",
            "Patches extracted: 48\n",
            "Now processing image: Document_Binarization_Collection/DP-LinkNet/dataset/IMG-20230804-WA0013.png\n",
            "Patches extracted: 48\n",
            "Now processing image: Document_Binarization_Collection/DP-LinkNet/dataset/IMG-20230804-WA0014.png\n",
            "Patches extracted: 48\n",
            "Now processing image: Document_Binarization_Collection/DP-LinkNet/dataset/WhatsApp Prent 2023-08-04 om 15.17.23.png\n",
            "Patches extracted: 12\n",
            "Total number of train patches: 492\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Document_Binarization_Collection/DP-LinkNet/train.py"
      ],
      "metadata": {
        "id": "UTSIQyiH5KfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python Document_Binarization_Collection/DP-LinkNet/test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dwyOOACdvU2",
        "outputId": "5aecc881-07e0-41d5-8ffd-e70f75227782"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image input directory: Document_Binarization_Collection/DP-LinkNet/test_set/\n",
            "Image output directory: Document_Binarization_Collection/DP-LinkNet/test_set/Binarized\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Now loading the model weights: Document_Binarization_Collection/DP-LinkNet/weights/dibco_dplinknet34.th\n",
            "Now processing image: IMG-20230804-WA0005.jpg\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "Now processing image: IMG-20230804-WA0006.jpg\n",
            "Now processing image: IMG-20230804-WA0007.jpg\n",
            "Now processing image: IMG-20230804-WA0008.jpg\n",
            "Now processing image: IMG-20230804-WA0009.jpg\n",
            "Now processing image: IMG-20230804-WA0010.jpg\n",
            "Now processing image: IMG-20230804-WA0011.jpg\n",
            "Now processing image: IMG-20230804-WA0012.jpg\n",
            "Now processing image: IMG-20230804-WA0013.jpg\n",
            "Now processing image: IMG-20230804-WA0014.jpg\n",
            "Now processing image: WhatsApp Prent 2023-08-04 om 15.17.23.jpg\n",
            "Total running time: 22.488048 sec.\n",
            "Finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test file\n",
        "import os\n",
        "from time import time\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable as V\n",
        "\n",
        "# from networks.unet import UNet\n",
        "# from networks.dunet import DUNet\n",
        "from networks.dplinknet import LinkNet34, DLinkNet34, DPLinkNet34\n",
        "from utils import get_patches, stitch_together\n",
        "\n",
        "BATCHSIZE_PER_CARD = 32\n",
        "\n",
        "\n",
        "class TTAFrame():\n",
        "    def __init__(self, net):\n",
        "        self.net = net().cuda()\n",
        "        self.net = torch.nn.DataParallel(self.net, device_ids=range(torch.cuda.device_count()))\n",
        "\n",
        "    def test_one_img_from_path(self, path, evalmode=True):\n",
        "        if evalmode:\n",
        "            self.net.eval()\n",
        "        batchsize = torch.cuda.device_count() * BATCHSIZE_PER_CARD\n",
        "        if batchsize >= 8:\n",
        "            return self.test_one_img_from_path_1(path)\n",
        "        elif batchsize >= 4:\n",
        "            return self.test_one_img_from_path_2(path)\n",
        "        elif batchsize >= 2:\n",
        "            return self.test_one_img_from_path_4(path)\n",
        "\n",
        "    def test_one_img_from_path_8(self, path):\n",
        "        img = np.array(path)  # .transpose(2,0,1)[None]\n",
        "        # img = cv2.imread(path)  # .transpose(2,0,1)[None]\n",
        "        img90 = np.array(np.rot90(img))\n",
        "        img1 = np.concatenate([img[None], img90[None]])\n",
        "        img2 = np.array(img1)[:, ::-1]\n",
        "        img3 = np.array(img1)[:, :, ::-1]\n",
        "        img4 = np.array(img2)[:, :, ::-1]\n",
        "\n",
        "        img1 = img1.transpose(0, 3, 1, 2)\n",
        "        img2 = img2.transpose(0, 3, 1, 2)\n",
        "        img3 = img3.transpose(0, 3, 1, 2)\n",
        "        img4 = img4.transpose(0, 3, 1, 2)\n",
        "\n",
        "        img1 = V(torch.Tensor(np.array(img1, np.float32) / 255.0 * 3.2 - 1.6).cuda())\n",
        "        img2 = V(torch.Tensor(np.array(img2, np.float32) / 255.0 * 3.2 - 1.6).cuda())\n",
        "        img3 = V(torch.Tensor(np.array(img3, np.float32) / 255.0 * 3.2 - 1.6).cuda())\n",
        "        img4 = V(torch.Tensor(np.array(img4, np.float32) / 255.0 * 3.2 - 1.6).cuda())\n",
        "\n",
        "        maska = self.net.forward(img1).squeeze().cpu().data.numpy()\n",
        "        maskb = self.net.forward(img2).squeeze().cpu().data.numpy()\n",
        "        maskc = self.net.forward(img3).squeeze().cpu().data.numpy()\n",
        "        maskd = self.net.forward(img4).squeeze().cpu().data.numpy()\n",
        "\n",
        "        mask1 = maska + maskb[:, ::-1] + maskc[:, :, ::-1] + maskd[:, ::-1, ::-1]\n",
        "        mask2 = mask1[0] + np.rot90(mask1[1])[::-1, ::-1]\n",
        "\n",
        "        return mask2\n",
        "\n",
        "    def test_one_img_from_path_4(self, path):\n",
        "        img = np.array(path)  # .transpose(2,0,1)[None]\n",
        "        # img = cv2.imread(path)  # .transpose(2,0,1)[None]\n",
        "        img90 = np.array(np.rot90(img))\n",
        "        img1 = np.concatenate([img[None], img90[None]])\n",
        "        img2 = np.array(img1)[:, ::-1]\n",
        "        img3 = np.array(img1)[:, :, ::-1]\n",
        "        img4 = np.array(img2)[:, :, ::-1]\n",
        "\n",
        "        img1 = img1.transpose(0, 3, 1, 2)\n",
        "        img2 = img2.transpose(0, 3, 1, 2)\n",
        "        img3 = img3.transpose(0, 3, 1, 2)\n",
        "        img4 = img4.transpose(0, 3, 1, 2)\n",
        "\n",
        "        img1 = V(torch.Tensor(np.array(img1, np.float32) / 255.0 * 3.2 - 1.6).cuda())\n",
        "        img2 = V(torch.Tensor(np.array(img2, np.float32) / 255.0 * 3.2 - 1.6).cuda())\n",
        "        img3 = V(torch.Tensor(np.array(img3, np.float32) / 255.0 * 3.2 - 1.6).cuda())\n",
        "        img4 = V(torch.Tensor(np.array(img4, np.float32) / 255.0 * 3.2 - 1.6).cuda())\n",
        "\n",
        "        maska = self.net.forward(img1).squeeze().cpu().data.numpy()\n",
        "        maskb = self.net.forward(img2).squeeze().cpu().data.numpy()\n",
        "        maskc = self.net.forward(img3).squeeze().cpu().data.numpy()\n",
        "        maskd = self.net.forward(img4).squeeze().cpu().data.numpy()\n",
        "\n",
        "        mask1 = maska + maskb[:, ::-1] + maskc[:, :, ::-1] + maskd[:, ::-1, ::-1]\n",
        "        mask2 = mask1[0] + np.rot90(mask1[1])[::-1, ::-1]\n",
        "\n",
        "        return mask2\n",
        "\n",
        "    def test_one_img_from_path_2(self, path):\n",
        "        img = np.array(path)  # .transpose(2,0,1)[None]\n",
        "        # img = cv2.imread(path)  # .transpose(2,0,1)[None]\n",
        "        img90 = np.array(np.rot90(img))\n",
        "        img1 = np.concatenate([img[None], img90[None]])\n",
        "        img2 = np.array(img1)[:, ::-1]\n",
        "        img3 = np.concatenate([img1, img2])\n",
        "        img4 = np.array(img3)[:, :, ::-1]\n",
        "        img5 = img3.transpose(0, 3, 1, 2)\n",
        "        img5 = np.array(img5, np.float32) / 255.0 * 3.2 - 1.6\n",
        "        img5 = V(torch.Tensor(img5).cuda())\n",
        "        img6 = img4.transpose(0, 3, 1, 2)\n",
        "        img6 = np.array(img6, np.float32) / 255.0 * 3.2 - 1.6\n",
        "        img6 = V(torch.Tensor(img6).cuda())\n",
        "\n",
        "        maska = self.net.forward(img5).squeeze().cpu().data.numpy()  # .squeeze(1)\n",
        "        maskb = self.net.forward(img6).squeeze().cpu().data.numpy()\n",
        "\n",
        "        mask1 = maska + maskb[:, :, ::-1]\n",
        "        mask2 = mask1[:2] + mask1[2:, ::-1]\n",
        "        mask3 = mask2[0] + np.rot90(mask2[1])[::-1, ::-1]\n",
        "\n",
        "        return mask3\n",
        "\n",
        "    def test_one_img_from_path_1(self, path):\n",
        "        img = np.array(path)  # .transpose(2,0,1)[None]\n",
        "        # img = cv2.imread(path)  # .transpose(2,0,1)[None]\n",
        "        img90 = np.array(np.rot90(img))\n",
        "        img1 = np.concatenate([img[None], img90[None]])\n",
        "        img2 = np.array(img1)[:, ::-1]\n",
        "        img3 = np.concatenate([img1, img2])\n",
        "        img4 = np.array(img3)[:, :, ::-1]\n",
        "        img5 = np.concatenate([img3, img4]).transpose(0, 3, 1, 2)\n",
        "        img5 = np.array(img5, np.float32) / 255.0 * 3.2 - 1.6\n",
        "        img5 = V(torch.Tensor(img5).cuda())\n",
        "\n",
        "        mask = self.net.forward(img5).squeeze().cpu().data.numpy()  # .squeeze(1)\n",
        "        mask1 = mask[:4] + mask[4:, :, ::-1]\n",
        "        mask2 = mask1[:2] + mask1[2:, ::-1]\n",
        "        mask3 = mask2[0] + np.rot90(mask2[1])[::-1, ::-1]\n",
        "\n",
        "        return mask3\n",
        "\n",
        "    def load(self, path):\n",
        "        self.net.load_state_dict(torch.load(path))\n",
        "\n",
        "\n",
        "TILE_SIZE = 256\n",
        "DATA_NAME = \"DIBCO\"  # BickleyDiary, DIBCO, PLM\n",
        "DEEP_NETWORK_NAME = \"DPLinkNet34\"  # LinkNet34, DLinkNet34, DPLinkNet34\n",
        "\n",
        "img_indir = \"Document_Binarization_Collection/DP-LinkNet/test_set/\"\n",
        "print(\"Image input directory:\", img_indir)\n",
        "\n",
        "img_outdir = os.path.join(img_indir, \"Binarized\")\n",
        "if not os.path.exists(img_outdir):\n",
        "    os.makedirs(img_outdir)\n",
        "print(\"Image output directory:\", img_outdir)\n",
        "\n",
        "img_list = os.listdir(img_indir)\n",
        "img_list.sort()\n",
        "\n",
        "if DEEP_NETWORK_NAME == \"DPLinkNet34\":\n",
        "    solver = TTAFrame(DPLinkNet34)\n",
        "elif DEEP_NETWORK_NAME == \"DLinkNet34\":\n",
        "    solver = TTAFrame(DLinkNet34)\n",
        "elif DEEP_NETWORK_NAME == \"LinkNet34\":\n",
        "    solver = TTAFrame(LinkNet34)\n",
        "else:\n",
        "    print(\"Deep network not found, please have a check!\")\n",
        "    exit(0)\n",
        "# print(solver.net)\n",
        "# summary(solver.net, input_size=(3, TILE_SIZE, TILE_SIZE))  # summary(your_model, input_size=(channels, H, W))\n",
        "\n",
        "print(\"Now loading the model weights:\", \"Document_Binarization_Collection/DP-LinkNet/weights/\" + DATA_NAME.lower() + \"_\" + DEEP_NETWORK_NAME.lower() + \".th\")\n",
        "solver.load(\"Document_Binarization_Collection/DP-LinkNet/weights/\" + DATA_NAME.lower() + \"_\" + DEEP_NETWORK_NAME.lower() + \".th\")\n",
        "\n",
        "start_time = time()\n",
        "for idx in range(len(img_list)):\n",
        "    if os.path.isdir(os.path.join(img_indir, img_list[idx])):\n",
        "        continue\n",
        "\n",
        "    print(\"Now processing image:\", img_list[idx])\n",
        "    fname, fext = os.path.splitext(img_list[idx])\n",
        "    img_input = os.path.join(img_indir, img_list[idx])\n",
        "    img_output = os.path.join(img_outdir, fname +\".png\")\n",
        "\n",
        "    img = cv2.imread(img_input)\n",
        "    locations, patches = get_patches(img, TILE_SIZE, TILE_SIZE)\n",
        "    masks = []\n",
        "    for idy in range(len(patches)):\n",
        "        msk = solver.test_one_img_from_path(patches[idy])\n",
        "        masks.append(msk)\n",
        "    prediction = stitch_together(locations, masks, tuple(img.shape[0:2]), TILE_SIZE, TILE_SIZE)\n",
        "    prediction[prediction >= 5.0] = 255\n",
        "    prediction[prediction < 5.0] = 0\n",
        "    # prediction = np.concatenate([prediction[:, :, None], prediction[:, :, None], prediction[:, :, None]], axis=2)\n",
        "    cv2.imwrite(img_output, prediction.astype(np.uint8))\n",
        "\n",
        "print(\"Total running time: %f sec.\" % (time() - start_time))\n",
        "print(\"Finished!\")"
      ],
      "metadata": {
        "id": "4o78ssx-bLAf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}